{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wfdb\n",
    "import glob\n",
    "import os\n",
    "import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = \"/Users/taniapazospuig/Desktop/bio/ptb-xl-a-large-publicly-available-electrocardiography-dataset-1.0.3/\"\n",
    "csv_path = os.path.join(base_dir, \"ptbxl_database.csv\")\n",
    "record_dir = os.path.join(base_dir, \"records500\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata\n",
    "variables = pd.read_csv(csv_path, index_col=0)\n",
    "\n",
    "# Find all .dat files from records500 with the raw ECG signals\n",
    "files = glob.glob(os.path.join(record_dir, \"**\", \"*.dat\"), recursive=True)\n",
    "\n",
    "# Extract ecg_id from filenames\n",
    "labels = [os.path.splitext(os.path.basename(f))[0] for f in files]\n",
    "ecg_ids = [int(label.split(\"_\")[0]) for label in labels]\n",
    "\n",
    "# Filter metadata to keep only rows for which we have actual ECG waveform files\n",
    "variables = variables.loc[variables.index.isin(ecg_ids)]\n",
    "\n",
    "# Reorder filtered metadata to match the order of the waveform files\n",
    "ordered_indices = [id for id in ecg_ids if id in variables.index]\n",
    "variables = variables.loc[ordered_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of variables: (21799, 27)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>patient_id</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>height</th>\n",
       "      <th>weight</th>\n",
       "      <th>nurse</th>\n",
       "      <th>site</th>\n",
       "      <th>device</th>\n",
       "      <th>recording_date</th>\n",
       "      <th>report</th>\n",
       "      <th>...</th>\n",
       "      <th>validated_by_human</th>\n",
       "      <th>baseline_drift</th>\n",
       "      <th>static_noise</th>\n",
       "      <th>burst_noise</th>\n",
       "      <th>electrodes_problems</th>\n",
       "      <th>extra_beats</th>\n",
       "      <th>pacemaker</th>\n",
       "      <th>strat_fold</th>\n",
       "      <th>filename_lr</th>\n",
       "      <th>filename_hr</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecg_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>13619.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1985-01-23 12:55:32</td>\n",
       "      <td>supraventrikulÄre ersatzsystole(n) interponier...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>VES</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>records100/00000/00020_lr</td>\n",
       "      <td>records500/00000/00020_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>3063.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>10.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AT-6     6</td>\n",
       "      <td>1987-05-10 17:22:51</td>\n",
       "      <td>trace only requested.</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>9</td>\n",
       "      <td>records100/00000/00771_lr</td>\n",
       "      <td>records500/00000/00771_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>4845.0</td>\n",
       "      <td>73.0</td>\n",
       "      <td>1</td>\n",
       "      <td>170.0</td>\n",
       "      <td>103.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AT-6 C 5.5</td>\n",
       "      <td>1986-09-12 10:22:10</td>\n",
       "      <td>premature ventricular contraction(s). sinus rh...</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>records100/00000/00297_lr</td>\n",
       "      <td>records500/00000/00297_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>11860.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>57.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>CS-12   E</td>\n",
       "      <td>1986-01-16 06:41:58</td>\n",
       "      <td>sinusrhythmus normales ekg</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>, alles,</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4</td>\n",
       "      <td>records100/00000/00120_lr</td>\n",
       "      <td>records500/00000/00120_hr</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>3977.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "      <td>167.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>AT-6     6</td>\n",
       "      <td>1987-04-25 19:35:42</td>\n",
       "      <td>sinus rhythm. normal ecg.</td>\n",
       "      <td>...</td>\n",
       "      <td>True</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3</td>\n",
       "      <td>records100/00000/00671_lr</td>\n",
       "      <td>records500/00000/00671_hr</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        patient_id   age  sex  height  weight  nurse  site      device  \\\n",
       "ecg_id                                                                   \n",
       "20         13619.0  56.0    0     NaN     NaN    2.0   0.0   CS-12   E   \n",
       "771         3063.0  63.0    0     NaN     NaN   10.0   1.0  AT-6     6   \n",
       "297         4845.0  73.0    1   170.0   103.0    1.0   1.0  AT-6 C 5.5   \n",
       "120        11860.0  45.0    1     NaN    57.0    2.0   0.0   CS-12   E   \n",
       "671         3977.0  76.0    1   167.0    45.0    3.0   1.0  AT-6     6   \n",
       "\n",
       "             recording_date  \\\n",
       "ecg_id                        \n",
       "20      1985-01-23 12:55:32   \n",
       "771     1987-05-10 17:22:51   \n",
       "297     1986-09-12 10:22:10   \n",
       "120     1986-01-16 06:41:58   \n",
       "671     1987-04-25 19:35:42   \n",
       "\n",
       "                                                   report  ...  \\\n",
       "ecg_id                                                     ...   \n",
       "20      supraventrikulÄre ersatzsystole(n) interponier...  ...   \n",
       "771                                 trace only requested.  ...   \n",
       "297     premature ventricular contraction(s). sinus rh...  ...   \n",
       "120                            sinusrhythmus normales ekg  ...   \n",
       "671                             sinus rhythm. normal ecg.  ...   \n",
       "\n",
       "       validated_by_human baseline_drift static_noise burst_noise  \\\n",
       "ecg_id                                                              \n",
       "20                   True            NaN          NaN         NaN   \n",
       "771                  True            NaN          NaN         NaN   \n",
       "297                  True            NaN          NaN         NaN   \n",
       "120                  True            NaN   , alles,           NaN   \n",
       "671                  True            NaN          NaN         NaN   \n",
       "\n",
       "        electrodes_problems  extra_beats  pacemaker  strat_fold  \\\n",
       "ecg_id                                                            \n",
       "20                      NaN          VES        NaN           9   \n",
       "771                     NaN          NaN        NaN           9   \n",
       "297                     NaN          NaN        NaN           7   \n",
       "120                     NaN          NaN        NaN           4   \n",
       "671                     NaN          NaN        NaN           3   \n",
       "\n",
       "                      filename_lr                filename_hr  \n",
       "ecg_id                                                        \n",
       "20      records100/00000/00020_lr  records500/00000/00020_hr  \n",
       "771     records100/00000/00771_lr  records500/00000/00771_hr  \n",
       "297     records100/00000/00297_lr  records500/00000/00297_hr  \n",
       "120     records100/00000/00120_lr  records500/00000/00120_hr  \n",
       "671     records100/00000/00671_lr  records500/00000/00671_hr  \n",
       "\n",
       "[5 rows x 27 columns]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Shape and preview\n",
    "print(\"Shape of variables:\", variables.shape) # Rows are ECGs and columns are metadata\n",
    "variables.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure the dataset is ready for model training, we first handled the missing values in the metadata. Columns with more than 50% missing values (`electrodes_problems`, `infarction_stadium1`, `infarction_stadium2`, `pacemaker`, etc.) or low relevance (`nurse`, `site`, `device`,etc.) were dropped as they offered little value for the classification task and would introduce unnecessary noise.\n",
    "\n",
    "For columns with moderate missingness but potential predictive value, such as `height` and `weight`, we imputed missing values using the median, which is a standard and robust method for handling numerical missing data.\n",
    "\n",
    "Categorical columns, such as `sex` and `report`, had their missing values imputed using the mode, ensuring that the dataset remained complete and consistent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns being dropped due to missing or low relevance:\n",
      "--------------------------------------------------\n",
      "height: 68.01% missing\n",
      "weight: 56.78% missing\n",
      "infarction_stadium1: 74.26% missing\n",
      "infarction_stadium2: 99.53% missing\n",
      "baseline_drift: 92.67% missing\n",
      "static_noise: 85.05% missing\n",
      "burst_noise: 97.19% missing\n",
      "electrodes_problems: 99.86% missing\n",
      "extra_beats: 91.06% missing\n",
      "pacemaker: 98.67% missing\n",
      "nurse: 6.76% missing\n",
      "site: 0.08% missing\n",
      "device: 0.00% missing\n",
      "recording_date: 0.00% missing\n",
      "validated_by: 43.02% missing\n",
      "\n",
      "Final cleaned metadata info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 21799 entries, 20 to 17905\n",
      "Data columns (total 12 columns):\n",
      " #   Column                        Non-Null Count  Dtype  \n",
      "---  ------                        --------------  -----  \n",
      " 0   patient_id                    21799 non-null  float64\n",
      " 1   age                           21799 non-null  float64\n",
      " 2   sex                           21799 non-null  int64  \n",
      " 3   report                        21799 non-null  object \n",
      " 4   scp_codes                     21799 non-null  object \n",
      " 5   heart_axis                    21799 non-null  object \n",
      " 6   second_opinion                21799 non-null  bool   \n",
      " 7   initial_autogenerated_report  21799 non-null  bool   \n",
      " 8   validated_by_human            21799 non-null  bool   \n",
      " 9   strat_fold                    21799 non-null  int64  \n",
      " 10  filename_lr                   21799 non-null  object \n",
      " 11  filename_hr                   21799 non-null  object \n",
      "dtypes: bool(3), float64(2), int64(2), object(5)\n",
      "memory usage: 1.7+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# TODO: Give credit to https://github.com/huseyincavusbi/SE_ECGNet/blob/main/SE_ECGNet.ipynb\n",
    "# Identify columns with more than 50% missing values\n",
    "missing_percentages = (variables.isnull().sum() / len(variables)) * 100\n",
    "high_missing_cols = missing_percentages[missing_percentages > 50].index.tolist()\n",
    "\n",
    "# Define additional low-relevance columns to drop manually\n",
    "additional_cols_to_drop = ['nurse', 'site', 'device', 'recording_date', 'validated_by']\n",
    "\n",
    "# Combine both lists of columns to drop\n",
    "cols_to_drop = high_missing_cols + additional_cols_to_drop\n",
    "\n",
    "# Print columns to be dropped\n",
    "print(\"Columns being dropped due to missing or low relevance:\")\n",
    "print(\"-\" * 50)\n",
    "for col in cols_to_drop:\n",
    "    if col in variables.columns:\n",
    "        print(f\"{col}: {missing_percentages.get(col, 0):.2f}% missing\")\n",
    "\n",
    "# Drop the identified columns\n",
    "variables_cleaned = variables.drop(columns=cols_to_drop)\n",
    "\n",
    "# Handle remaining missing values\n",
    "# Fill numeric columns with median\n",
    "numeric_columns = variables_cleaned.select_dtypes(include=['float64', 'int64']).columns\n",
    "variables_cleaned[numeric_columns] = variables_cleaned[numeric_columns].fillna(variables_cleaned[numeric_columns].median())\n",
    "\n",
    "# Fill categorical columns with mode\n",
    "categorical_columns = variables_cleaned.select_dtypes(include=['object']).columns\n",
    "variables_cleaned[categorical_columns] = variables_cleaned[categorical_columns].fillna(variables_cleaned[categorical_columns].mode().iloc[0])\n",
    "\n",
    "print(\"\\nFinal cleaned metadata info:\")\n",
    "print(variables_cleaned.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Missing values per column:\n",
      "patient_id                      0\n",
      "age                             0\n",
      "sex                             0\n",
      "report                          0\n",
      "scp_codes                       0\n",
      "heart_axis                      0\n",
      "second_opinion                  0\n",
      "initial_autogenerated_report    0\n",
      "validated_by_human              0\n",
      "strat_fold                      0\n",
      "filename_lr                     0\n",
      "filename_hr                     0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"\\nMissing values per column:\")\n",
    "print(variables_cleaned.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the PTB-XL dataset, patient age is provided at the time of ECG recording. However, in compliance with HIPAA privacy standards, all patients older than 89 years are assigned a value of 300. This is a form of pseudonymization to prevent potential re-identification of elderly individuals. Since this value does not represent a real age and could skew the model or statistical summaries, we cap all age values at 89."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sex distribution:\n",
      " sex\n",
      "0    11354\n",
      "1    10445\n",
      "Name: count, dtype: int64 \n",
      "\n",
      "Age summary:\n",
      " count    21799.000000\n",
      "mean        62.769301\n",
      "std         32.308813\n",
      "min          2.000000\n",
      "25%         50.000000\n",
      "50%         62.000000\n",
      "75%         72.000000\n",
      "max        300.000000\n",
      "Name: age, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Sex distribution:\\n\", variables_cleaned[\"sex\"].value_counts(), \"\\n\")\n",
    "print(\"Age summary:\\n\", variables_cleaned[\"age\"].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cap age at 89\n",
    "variables_cleaned[\"age\"] = variables_cleaned[\"age\"].apply(lambda x: 89 if x == 300 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ecg_id\n",
       "20                 {'AFLT': 100.0, 'ABQRS': 0.0}\n",
       "771                              {'NORM': 100.0}\n",
       "297        {'NORM': 80.0, 'PVC': 0.0, 'SR': 0.0}\n",
       "120                   {'NORM': 100.0, 'SR': 0.0}\n",
       "671                   {'NORM': 100.0, 'SR': 0.0}\n",
       "                          ...                   \n",
       "17141                  {'NDT': 100.0, 'SR': 0.0}\n",
       "17710                  {'NORM': 80.0, 'SR': 0.0}\n",
       "17041                {'CLBBB': 100.0, 'SR': 0.0}\n",
       "17805    {'NORM': 80.0, 'HVOLT': 0.0, 'SR': 0.0}\n",
       "17905                  {'NDT': 100.0, 'SR': 0.0}\n",
       "Name: scp_codes, Length: 21799, dtype: object"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "variables_cleaned[\"scp_codes\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multi-label classification is required for this task because each ECG record can be associated with multiple diagnostic superclasses (`NORM`, `MI`, `STTC`, `CD`, `HYP`). To simplify the task and focus on the required classes for this assignment, we decided to focus on the three target labels: `NORM`, `MI`, and `STTC`.\n",
    "\n",
    "To ensure the dataset only contains records relevant to these classes, we filtered out any records that did not include at least one of the three target labels (`NORM`, `MI`, `STTC`), ensuring that the model will only be trained and evaluated on these three superclasses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "\n",
    "def safe_literal_eval(val):\n",
    "    if isinstance(val, str):\n",
    "        return literal_eval(val)\n",
    "    return val  # Already a dict, no need to convert\n",
    "\n",
    "variables_cleaned[\"scp_codes\"] = variables_cleaned[\"scp_codes\"].apply(safe_literal_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scp_codes</th>\n",
       "      <th>diagnostic_superclass_mapped</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecg_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>{'AFLT': 100.0, 'ABQRS': 0.0}</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>{'NORM': 100.0}</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>{'NORM': 80.0, 'PVC': 0.0, 'SR': 0.0}</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>{'ASMI': 100.0, 'ILBBB': 100.0, 'LVH': 100.0, ...</td>\n",
       "      <td>[HYP, MI, STTC, CD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>{'ISCIN': 100.0, '1AVB': 100.0, 'PVC': 100.0, ...</td>\n",
       "      <td>[STTC, CD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>{'SEHYP': 50.0, 'ISCAS': 100.0, 'INVT': 0.0, '...</td>\n",
       "      <td>[HYP, STTC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                scp_codes  \\\n",
       "ecg_id                                                      \n",
       "20                          {'AFLT': 100.0, 'ABQRS': 0.0}   \n",
       "771                                       {'NORM': 100.0}   \n",
       "297                 {'NORM': 80.0, 'PVC': 0.0, 'SR': 0.0}   \n",
       "120                            {'NORM': 100.0, 'SR': 0.0}   \n",
       "671                            {'NORM': 100.0, 'SR': 0.0}   \n",
       "397                            {'NORM': 100.0, 'SR': 0.0}   \n",
       "964     {'ASMI': 100.0, 'ILBBB': 100.0, 'LVH': 100.0, ...   \n",
       "864     {'ISCIN': 100.0, '1AVB': 100.0, 'PVC': 100.0, ...   \n",
       "919     {'SEHYP': 50.0, 'ISCAS': 100.0, 'INVT': 0.0, '...   \n",
       "819                            {'NORM': 100.0, 'SR': 0.0}   \n",
       "\n",
       "       diagnostic_superclass_mapped  \n",
       "ecg_id                               \n",
       "20                               []  \n",
       "771                          [NORM]  \n",
       "297                          [NORM]  \n",
       "120                          [NORM]  \n",
       "671                          [NORM]  \n",
       "397                          [NORM]  \n",
       "964             [HYP, MI, STTC, CD]  \n",
       "864                      [STTC, CD]  \n",
       "919                     [HYP, STTC]  \n",
       "819                          [NORM]  "
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load statement reference table\n",
    "scp_df = pd.read_csv(os.path.join(base_dir, \"scp_statements.csv\"), index_col=0)\n",
    "\n",
    "# Keep only rows with a diagnostic_class\n",
    "scp_diagnostic_map = scp_df[scp_df[\"diagnostic_class\"].notnull()][\"diagnostic_class\"].to_dict()\n",
    "\n",
    "# Map each scp_codes dict to diagnostic superclasses\n",
    "def map_to_superclasses(scp_code_dict):\n",
    "    return list({scp_diagnostic_map[code] for code in scp_code_dict if code in scp_diagnostic_map})\n",
    "\n",
    "variables_cleaned[\"diagnostic_superclass_mapped\"] = variables_cleaned[\"scp_codes\"].apply(map_to_superclasses)\n",
    "\n",
    "variables_cleaned[[\"scp_codes\", \"diagnostic_superclass_mapped\"]].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>scp_codes</th>\n",
       "      <th>diagnostic_superclass_mapped</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ecg_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>771</th>\n",
       "      <td>{'NORM': 100.0}</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>297</th>\n",
       "      <td>{'NORM': 80.0, 'PVC': 0.0, 'SR': 0.0}</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>120</th>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>671</th>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>397</th>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>964</th>\n",
       "      <td>{'ASMI': 100.0, 'ILBBB': 100.0, 'LVH': 100.0, ...</td>\n",
       "      <td>[HYP, MI, STTC, CD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>864</th>\n",
       "      <td>{'ISCIN': 100.0, '1AVB': 100.0, 'PVC': 100.0, ...</td>\n",
       "      <td>[STTC, CD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>{'SEHYP': 50.0, 'ISCAS': 100.0, 'INVT': 0.0, '...</td>\n",
       "      <td>[HYP, STTC]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>{'NORM': 100.0, 'SR': 0.0}</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>{'NORM': 80.0, 'VCLVH': 0.0, 'SBRAD': 0.0}</td>\n",
       "      <td>[NORM]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                scp_codes  \\\n",
       "ecg_id                                                      \n",
       "771                                       {'NORM': 100.0}   \n",
       "297                 {'NORM': 80.0, 'PVC': 0.0, 'SR': 0.0}   \n",
       "120                            {'NORM': 100.0, 'SR': 0.0}   \n",
       "671                            {'NORM': 100.0, 'SR': 0.0}   \n",
       "397                            {'NORM': 100.0, 'SR': 0.0}   \n",
       "964     {'ASMI': 100.0, 'ILBBB': 100.0, 'LVH': 100.0, ...   \n",
       "864     {'ISCIN': 100.0, '1AVB': 100.0, 'PVC': 100.0, ...   \n",
       "919     {'SEHYP': 50.0, 'ISCAS': 100.0, 'INVT': 0.0, '...   \n",
       "819                            {'NORM': 100.0, 'SR': 0.0}   \n",
       "289            {'NORM': 80.0, 'VCLVH': 0.0, 'SBRAD': 0.0}   \n",
       "\n",
       "       diagnostic_superclass_mapped  \n",
       "ecg_id                               \n",
       "771                          [NORM]  \n",
       "297                          [NORM]  \n",
       "120                          [NORM]  \n",
       "671                          [NORM]  \n",
       "397                          [NORM]  \n",
       "964             [HYP, MI, STTC, CD]  \n",
       "864                      [STTC, CD]  \n",
       "919                     [HYP, STTC]  \n",
       "819                          [NORM]  \n",
       "289                          [NORM]  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the 3 target labels\n",
    "target_labels = {\"NORM\", \"MI\", \"STTC\"}\n",
    "\n",
    "# Keep records that have at least one of the target labels\n",
    "variables_filtered = variables_cleaned[variables_cleaned[\"diagnostic_superclass_mapped\"].apply(lambda x: bool(set(x) & target_labels))]\n",
    "\n",
    "variables_filtered[[\"scp_codes\", \"diagnostic_superclass_mapped\"]].head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The multi-hot encoding approach was used to represent the target labels for each ECG. `MultiLabelBinarizer` was applied to convert the `diagnostic_superclass_mapped` column (which contains lists of superclasses) into a binary matrix, where each row represents an ECG and each column corresponds to the presence (1) or absence (0) of one of the target labels. Labels such as `CD` and `HYP` were intentionally excluded from this encoding, as they are outside the scope of the task and should not influence model predictions or evaluation.\n",
    "\n",
    "This approach allows the model to learn which of the target classes (`NORM`, `MI`, `STTC`) are associated with each ECG, even if multiple labels are present."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taniapazospuig/anaconda3/envs/CompBioMed25/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:900: UserWarning: unknown class(es) ['CD', 'HYP'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "mlb = MultiLabelBinarizer(classes=[\"NORM\", \"MI\", \"STTC\"])\n",
    "y = mlb.fit_transform(variables_filtered[\"diagnostic_superclass_mapped\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To ensure proper evaluation and generalization of the classification models, we followed the official 10-fold stratified split provided by the PTB-XL dataset authors. This split keeps all records from the same patient within the same fold, avoiding data leakage.\n",
    "\n",
    "Specifically, we used:\n",
    "- Folds 1–8 for training\n",
    "- Fold 9 for validation\n",
    "- Fold 10 for testing\n",
    "\n",
    "We then loaded the corresponding ECG signal data using the paths provided in the `filename_hr` column. Signals were loaded at a sampling rate of 500 Hz, preserving full resolution for better model performance.\n",
    "The label vectors (`y_train`, `y_val`, `y_test`) were already multi-hot encoded using the `MultiLabelBinarizer`, allowing the model to learn from ECGs with multiple diagnostic labels (`NORM`, `MI`, `STTC`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/taniapazospuig/anaconda3/envs/CompBioMed25/lib/python3.8/site-packages/sklearn/preprocessing/_label.py:900: UserWarning: unknown class(es) ['CD', 'HYP'] will be ignored\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "fs = 500\n",
    "\n",
    "# Load ECG signal data\n",
    "def load_raw_data(df, fs, base_path):\n",
    "    if fs == 100:\n",
    "        paths = df[\"filename_lr\"]\n",
    "    else:\n",
    "        paths = df[\"filename_hr\"]\n",
    "    signals = []\n",
    "    for f in paths:\n",
    "        full_path = os.path.join(base_path, f)\n",
    "        signal, _ = wfdb.rdsamp(full_path)\n",
    "        signals.append(signal)\n",
    "    return np.array(signals)\n",
    "\n",
    "# Split variables_filtered by strat_fold\n",
    "train_df = variables_filtered[variables_filtered[\"strat_fold\"] < 9]\n",
    "val_df   = variables_filtered[variables_filtered[\"strat_fold\"] == 9]\n",
    "test_df  = variables_filtered[variables_filtered[\"strat_fold\"] == 10]\n",
    "\n",
    "# Load raw signal data\n",
    "X_train = load_raw_data(train_df, fs, base_dir)\n",
    "X_val   = load_raw_data(val_df, fs, base_dir)\n",
    "X_test  = load_raw_data(test_df, fs, base_dir)\n",
    "\n",
    "# Get binarized labels using the same mlb\n",
    "y_train = mlb.transform(train_df[\"diagnostic_superclass_mapped\"])\n",
    "y_val   = mlb.transform(val_df[\"diagnostic_superclass_mapped\"])\n",
    "y_test  = mlb.transform(test_df[\"diagnostic_superclass_mapped\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluated the quality of ECG signals using the Signal-to-Noise Ratio (SNR) across all 12 leads in the training set.\n",
    "Since raw ECGs do not have clean ground truth references, we computed:\n",
    "- Pre-filter SNR by estimating signal power vs. variance (as a proxy for noise)\n",
    "- Post-filter SNR by treating the filtered signal as the clean reference and computing noise as the difference between the raw and filtered signals\n",
    "\n",
    "The results show a consistent and significant improvement in SNR after applying standard filtering (0.5 Hz high-pass, 45 Hz low-pass, and detrending)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 100\n",
    "num_leads = X_train.shape[2]\n",
    "\n",
    "# Compute SNR of raw signals (before filtering)\n",
    "# Before filtering, we do not have a clean signal to compare to\n",
    "# We use the raw signal to compute its power, and its variance to estimate noise\n",
    "def compute_raw_snr_batch(X):\n",
    "    signal_power_total = np.zeros(num_leads)\n",
    "    noise_power_total = np.zeros(num_leads)\n",
    "\n",
    "    for i in range(0, len(X), batch_size):\n",
    "        batch = X[i:i+batch_size]\n",
    "\n",
    "        for signal_raw in batch:\n",
    "            # Compute average signal power per lead\n",
    "            signal_power = np.mean(np.square(signal_raw), axis=0)\n",
    "\n",
    "            # Estimate noise power per lead as the variance (std^2)\n",
    "            noise_power = np.var(signal_raw, axis=0)\n",
    "\n",
    "            signal_power_total += signal_power\n",
    "            noise_power_total += noise_power\n",
    "\n",
    "    # Average over all ECGs\n",
    "    P_signal_avg = signal_power_total / len(X)\n",
    "    P_noise_avg = noise_power_total / len(X)\n",
    "\n",
    "    # Compute SNR and convert to decibels\n",
    "    snr = P_signal_avg / P_noise_avg\n",
    "    snr_db = 10 * np.log10(snr)\n",
    "\n",
    "    return snr, snr_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import signal\n",
    "\n",
    "# Filtering function\n",
    "def apply_filters(ecg, fs):\n",
    "    # High-pass filter\n",
    "    ecg = signal.filtfilt(*signal.butter(2, 0.5, 'high', fs=fs), ecg, axis=0)\n",
    "    # Low-pass filter\n",
    "    ecg = signal.filtfilt(*signal.butter(2, 45.0, 'low', fs=fs), ecg, axis=0)\n",
    "    # Remove linear trend\n",
    "    ecg = signal.detrend(ecg, axis=0)\n",
    "    return ecg\n",
    "\n",
    "# Compute SNR in batches to avoid memory issues\n",
    "def compute_power_snr_batch(X, fs):\n",
    "    signal_power_total = np.zeros(num_leads)\n",
    "    noise_power_total = np.zeros(num_leads)\n",
    "    \n",
    "    for i in range(0, len(X), batch_size):\n",
    "        batch = X[i:i+batch_size]\n",
    "        \n",
    "        # Split the data into batches\n",
    "        for signal_raw in batch:\n",
    "            signal_filtered = apply_filters(signal_raw, fs)\n",
    "            noise = signal_raw - signal_filtered\n",
    "\n",
    "            # Compute average power per lead for clean and noisy signals\n",
    "            signal_power = np.mean(np.square(signal_filtered), axis=0)\n",
    "            noise_power = np.mean(np.square(noise), axis=0)\n",
    "\n",
    "            signal_power_total += signal_power\n",
    "            noise_power_total += noise_power\n",
    "\n",
    "    # Average over all processed signals\n",
    "    P_signal_avg = signal_power_total / len(X)\n",
    "    P_noise_avg = noise_power_total / len(X)\n",
    "    snr = P_signal_avg / P_noise_avg\n",
    "    snr_db = 10 * np.log10(snr)\n",
    "\n",
    "    return snr, snr_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lead  Raw SNR (dB)   Filtered SNR (dB)   Delta SNR (dB)\n",
      "--------------------------------------------------\n",
      "1     0.20           1.62                1.42      \n",
      "2     0.09           6.04                5.96      \n",
      "3     0.30           2.77                2.47      \n",
      "4     0.15           6.34                6.19      \n",
      "5     0.35           3.07                2.72      \n",
      "6     0.16           4.09                3.93      \n",
      "7     0.02           4.84                4.81      \n",
      "8     0.01           7.93                7.93      \n",
      "9     0.01           6.50                6.49      \n",
      "10    0.00           7.38                7.38      \n",
      "11    0.39           3.56                3.17      \n",
      "12    0.01           2.68                2.67      \n"
     ]
    }
   ],
   "source": [
    "# Compute SNR before filtering\n",
    "snr_raw, snr_raw_db = compute_raw_snr_batch(X_train)\n",
    "\n",
    "# Compute SNR after filtering\n",
    "snr_filtered, snr_filtered_db = compute_power_snr_batch(X_train, fs=500)\n",
    "\n",
    "# Display the results per lead\n",
    "print(f\"{'Lead':<6}{'Raw SNR (dB)':<15}{'Filtered SNR (dB)':<20}{'Delta SNR (dB)':<10}\")\n",
    "print(\"-\" * 50)\n",
    "for i in range(num_leads):\n",
    "    delta = snr_filtered_db[i] - snr_raw_db[i]\n",
    "    print(f\"{i+1:<6}{snr_raw_db[i]:<15.2f}{snr_filtered_db[i]:<20.2f}{delta:<10.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Store filtered signals for later steps\n",
    "X_train_filtered = np.array([apply_filters(x, fs=500) for x in X_train])\n",
    "X_val_filtered   = np.array([apply_filters(x, fs=500) for x in X_val])\n",
    "X_test_filtered  = np.array([apply_filters(x, fs=500) for x in X_test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "CompBioMed25",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
